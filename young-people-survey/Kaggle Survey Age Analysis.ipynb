{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# styling\n",
    "pd.set_option('display.max_columns',150)\n",
    "plt.style.use('bmh')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:\\\\Users\\\\jmpl\\\\Documents\\\\Data_Science\\\\Kaggle\\\\young-people-survey\\\\columns.csv' does not exist: b'C:\\\\Users\\\\jmpl\\\\Documents\\\\Data_Science\\\\Kaggle\\\\young-people-survey\\\\columns.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f89bbca308e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# young = pd.read_csv(r'/Users/jaimin/Documents/Kaggle/Kaggle-young-people-survey/young-people-survey/responses.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\jmpl\\Documents\\Data_Science\\Kaggle\\young-people-survey\\columns.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0myoung\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\jmpl\\Documents\\Data_Science\\Kaggle\\young-people-survey\\responses.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    695\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:\\\\Users\\\\jmpl\\\\Documents\\\\Data_Science\\\\Kaggle\\\\young-people-survey\\\\columns.csv' does not exist: b'C:\\\\Users\\\\jmpl\\\\Documents\\\\Data_Science\\\\Kaggle\\\\young-people-survey\\\\columns.csv'"
     ]
    }
   ],
   "source": [
    "# Columns contain the data headers and responses contains the actual data\n",
    "\n",
    "columns = pd.read_csv(r'C:\\Users\\jmpl\\Documents\\Data_Science\\Kaggle\\young-people-survey\\columns.csv')\n",
    "young = pd.read_csv(r'C:\\Users\\jmpl\\Documents\\Data_Science\\Kaggle\\young-people-survey\\responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "young.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(young['Age'].mean())\n",
    "print(young['Age'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(young['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Distinguish young and old from and less 20 and over 20\n",
    "# Looking for inferences which distinguish the young generation (< 20) and the older generation (>= 20)\n",
    "# Expecting differences to be around social behaviour: partying & socialising etc., Smoking & Drinking, No. of friends. Mood changes., Different spending habits, education level received\n",
    "\n",
    "print(len(young['Gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Age either younger than 20 or 20 or over\n",
    "young['Under 20'] = np.where(young['Age'] < 20, 'Younger', 'Older') \n",
    "\n",
    "print(young['Under 20'].head())\n",
    "\n",
    "# seriesObj = young.apply(lambda x: True if x['Age'] > 19 else False, axis = 1)\n",
    "\n",
    "num_under20 = len(young['Under 20'][young['Under 20'] ==  'Younger'].index)\n",
    "print(num_under20)\n",
    "\n",
    "num_over20 = len(young['Under 20'][young['Under 20'] ==  'Older'].index)\n",
    "print(num_over20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_of_interest = 'Under 20'\n",
    "mapping = {var_of_interest: {'Younger': 0, 'Older': 1}}\n",
    "young.dropna(subset=[var_of_interest], inplace=True)\n",
    "# to be able to use hue parameter for better comparison in seaborn\n",
    "young[\"all\"] = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,6))\n",
    "sns.countplot(x = var_of_interest, data = young, ax = ax[0])\n",
    "sns.countplot(x = var_of_interest, hue = 'Gender' , data = young, ax = ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Looking at the difference in proportion of male and female for the age groups\n",
    "\n",
    "data = young\n",
    "sns.violinplot(x = 'Age', y = 'all', hue = 'Gender', data = data, split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def do_ploting(x, y, figsize):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title(\"Correlation coefficient of the variables\")\n",
    "    sns.barplot(x=x, y=y, ax=ax)\n",
    "    ax.set_ylabel(\"Correlation coefficients\")\n",
    "\n",
    "\n",
    "def correlation_plot(var_of_interest, df_main, mapping, figsize=(10, 30)):\n",
    "    def calc_corr(var_of_interest, df, cols, figsize):\n",
    "        lbls = []\n",
    "        vals = []\n",
    "        for col in cols:\n",
    "            lbls.append(col)\n",
    "            vals.append(np.corrcoef(df[col], df[var_of_interest])[0, 1])\n",
    "        corrs = pd.DataFrame({'features': lbls, 'corr_values': vals})\n",
    "        corrs = corrs.sort_values(by='corr_values')\n",
    "        do_ploting(corrs.corr_values, corrs['features'], figsize)\n",
    "        return corrs\n",
    "\n",
    "    #imputing the set\n",
    "    df = copy.deepcopy(df_main)\n",
    "    df.replace(mapping, inplace=True)\n",
    "    mean_values = df.mean(axis=0)\n",
    "    df.fillna(mean_values, inplace=True)\n",
    "\n",
    "    #correlating non-categorical varibales\n",
    "    cols_floats = [col for col in df.columns if df[col].dtype != 'object']\n",
    "    cols_floats.remove(var_of_interest)\n",
    "    corrs_one = calc_corr(var_of_interest, df, cols_floats, figsize)\n",
    "\n",
    "    #correlating categorical variables\n",
    "    cols_cats = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    if cols_cats:\n",
    "        df_dummies = pd.get_dummies(df[cols_cats])\n",
    "        cols_cats = df_dummies.columns\n",
    "        df_dummies[var_of_interest] = df[var_of_interest]\n",
    "        corrs_two = calc_corr(var_of_interest, df_dummies, cols_cats, (5, 10))\n",
    "    else:\n",
    "        corrs_two = 0\n",
    "    return [corrs_one, corrs_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop age for correlation\n",
    "del young['Age']\n",
    "\n",
    "corrs_area = correlation_plot(var_of_interest, young, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reducing multicolinearity, change for other\n",
    "corr = young.corr()\n",
    "os = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool)).stack().sort_values(ascending=False))\n",
    "\n",
    "# drop_colinera_cols = os[abs(os)>0.5].reset_index()['level_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Machine Learning Used Here\n",
    "# Data preprocessing\n",
    "\n",
    "features_int = [col for col in young.columns if young[col].dtype != 'object']\n",
    "\n",
    "features_cats = [col for col in young.columns if young[col].dtype == 'object']\n",
    "print(len(features_cats))\n",
    "print(len(features_int))\n",
    "\n",
    "\n",
    "print(features_cats)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(features_int)\n",
    "\n",
    "\n",
    "\n",
    "# features_int = list(set(features_int) - set(drop_colinera_cols))\n",
    "features_int = list(set(features_int))\n",
    "print(len(features_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = young[features_int]\n",
    "mean_values = X.mean(axis=0)\n",
    "X = X.apply(lambda x: x.fillna(x.mean()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y = young[var_of_interest]\n",
    "\n",
    "for key, val in mapping[var_of_interest].items():\n",
    "    Y.replace(key,val, inplace = True)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gridsearch for parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clr = LogisticRegression()\n",
    "KF = KFold(n_splits = 5)\n",
    "param_grid = {'C':[.001,.01,.03,.1,.3,1,3,10]}\n",
    "grsearch = GridSearchCV(clr, param_grid=param_grid, cv=KF, scoring = 'f1')\n",
    "grsearch.fit(x_train, y_train)\n",
    "print(grsearch.best_params_)\n",
    "\n",
    "# fitting logistic regression and evaluating\n",
    "clr = LogisticRegression(C=grsearch.best_params_['C'])\n",
    "clr.fit(x_train, y_train)\n",
    "\n",
    "mean_accuracy = np.mean(cross_val_score(clr, x_train, y_train, cv=KF))\n",
    "print('Average accuracy score on CV set: {:.2f}'.format(mean_accuracy))\n",
    "\n",
    "mean_f1 = np.mean(cross_val_score(clr, x_train, y_train, cv=KF, scoring = 'f1'))\n",
    "print('Average f1 on CV set: {:.2f}'.format(mean_f1))\n",
    "print('')\n",
    "print('Accuracy score on test set is: {:.2f}'.format(clr.score(x_test, y_test)))\n",
    "recall = recall_score(y_test, clr.predict(x_test))\n",
    "print ('Recall on test: {:.2f}'.format(recall))\n",
    "precision = precision_score(y_test, clr.predict(x_test))\n",
    "print ('Presicion on test: {:.2f}'.format(precision))\n",
    "print ('F1 score on test: {:.2f}'.format((2*recall*precision /(recall + precision))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gridsearch for parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clr = LogisticRegression()\n",
    "KF = KFold(len(x_train)) # LOOCV\n",
    "param_grid = {'C':[.001,.01,.03,.1,.3,1,3,10]}\n",
    "grsearch = GridSearchCV(clr, param_grid=param_grid, cv=KF, scoring = 'f1')\n",
    "grsearch.fit(x_train, y_train)\n",
    "print(grsearch.best_params_)\n",
    "\n",
    "# fitting logistic regression and evaluating\n",
    "clr = LogisticRegression(C=grsearch.best_params_['C'])\n",
    "clr.fit(x_train, y_train)\n",
    "\n",
    "mean_accuracy = np.mean(cross_val_score(clr, x_train, y_train, cv=KF))\n",
    "print('Average accuracy score on CV set: {:.2f}'.format(mean_accuracy))\n",
    "\n",
    "mean_f1 = np.mean(cross_val_score(clr, x_train, y_train, cv=KF, scoring = 'f1'))\n",
    "print('Average f1 on CV set: {:.2f}'.format(mean_f1))\n",
    "print('')\n",
    "print('Accuracy score on test set is: {:.2f}'.format(clr.score(x_test, y_test)))\n",
    "recall = recall_score(y_test, clr.predict(x_test))\n",
    "print ('Recall on test: {:.2f}'.format(recall))\n",
    "precision = precision_score(y_test, clr.predict(x_test))\n",
    "print ('Presicion on test: {:.2f}'.format(precision))\n",
    "print ('F1 score on test: {:.2f}'.format((2*recall*precision /(recall + precision))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_coeff = pd.DataFrame({'features': X.columns,'impacts': clr.coef_[0]})\n",
    "feat_coeff = feat_coeff.sort_values('impacts', ascending=False)\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(30,6));\n",
    "sns.barplot(x=feat_coeff.features, y=feat_coeff.impacts, ax=ax1);\n",
    "ax1.set_title('All features', size=30);\n",
    "ax1.set_xticklabels(labels=feat_coeff.features, size=20, rotation=90);\n",
    "ax1.set_ylabel('Impact', size=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10 = pd.concat([feat_coeff.head(6),feat_coeff.tail(6)])\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "sns.barplot(y=top10.features, x=top10.impacts, ax=ax1);\n",
    "ax1.set_title('Top 12 features', size=20);\n",
    "ax1.set_yticklabels(labels=top10.features, size=15);\n",
    "ax1.set_xlabel('Impact', size=20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis of factors which have the greatest influence those who drink a lot vs. those who don't drink or only socially drink\n",
    "\n",
    "clean_data = young.dropna(subset=['Alcohol'])\n",
    "features_int = [col for col in clean_data.columns if clean_data[col].dtype!='object']\n",
    "X = clean_data[features_int]\n",
    "mean_values = X.mean(axis=0)\n",
    "X = X.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "Y = clean_data['Alcohol']\n",
    "Y.replace('never',0, inplace = True)\n",
    "Y.replace('social drinker',0, inplace = True)\n",
    "Y.replace('drink a lot',1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "clr = LogisticRegression()\n",
    "clr.fit(X, Y)\n",
    "feat_coeff = pd.DataFrame({'features': features_int,'impacts': clr.coef_[0]})\n",
    "feat_coeff = feat_coeff.sort_values('impacts', ascending=False)\n",
    "feat_coeff.drop([73], inplace = True)\n",
    "\n",
    "top10 = pd.concat([feat_coeff.head(8),feat_coeff.tail(8)])\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "sns.barplot(y=top10.features, x=top10.impacts, ax=ax1);\n",
    "ax1.set_title('Top 16 features', size=20);\n",
    "ax1.set_yticklabels(labels=top10.features, size=15);\n",
    "ax1.set_xlabel('Impact', size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis of factors which have the greatest influence those who smoke or have smoked vs. those who don't smoke\n",
    "\n",
    "clean_data = young.dropna(subset=['Smoking'])\n",
    "features_int = [col for col in clean_data.columns if clean_data[col].dtype!='object']\n",
    "X = clean_data[features_int]\n",
    "mean_values = X.mean(axis=0)\n",
    "X = X.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "Y = clean_data['Smoking']\n",
    "Y.replace('never smoked',0, inplace = True)\n",
    "Y.replace('tried smoking',1, inplace = True)\n",
    "Y.replace('current smoker',1, inplace = True)\n",
    "Y.replace('current smoker',1, inplace = True)\n",
    "Y.replace('former smoker',1, inplace = True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "clr = LogisticRegression()\n",
    "clr.fit(X, Y)\n",
    "feat_coeff = pd.DataFrame({'features': features_int,'impacts': clr.coef_[0]})\n",
    "feat_coeff = feat_coeff.sort_values('impacts', ascending=False)\n",
    "\n",
    "top10 = pd.concat([feat_coeff.head(8),feat_coeff.tail(8)])\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "sns.barplot(y=top10.features, x=top10.impacts, ax=ax1);\n",
    "ax1.set_title('Top 16 features', size=20);\n",
    "ax1.set_yticklabels(labels=top10.features, size=15);\n",
    "ax1.set_xlabel('Impact', size=20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
